{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd3391-06d9-4e88-9688-6c0d34449dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSIGNMENT MACHINE L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08015a87-4601-46dd-ac2d-dfb08dfdc26e",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10397d08-88bd-4c33-ae29-6cb08263e914",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "Overfitting happens when we train a machine learning model too much tuned to the training set. As a result, the model learns the training data too well, but it can’t generate good predictions for unseen data. An overfitted model produces low accuracy results for data points unseen in training, hence, leads to non-optimal decisions.\n",
    "\n",
    "An underfitted model is not complex enough to recognize the patterns in the dataset. Usually, it has a high bias towards one output value. This is because it considers the variations of the input data as noise and generates similar outputs regardless of the given input.When training a model, we want it to fit well to the training data. Still, we want it to generalize and generate accurate predictions for unseen data, as well. \n",
    "The cause for overfitting is a misinterpretation of training data. So, the model produces less accurate results for unseen data. However, an overfitted model generates very high accuracy scores during the training phase.\n",
    "\n",
    "Similarly, underfitted models don’t effectively capture the relationship between the input and output data because it is too simple. As a result, the underfitted model performs poorly, even with the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c94b3b9-e900-440b-aae7-7c9936742adc",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e2329-6230-4846-aa43-43361e7707a1",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "The most robust method to reduce overfitting is collect more data. The more data we have, the easier it is to explore and model the underlying structure. The methods we will discuss in this article are based on the assumption that it is not possible to collect more data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4170de-b988-44e1-be6e-89f7e6c56a5f",
   "metadata": {},
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1362f1b2-0782-42e1-ace1-bb1f6b0e54b9",
   "metadata": {},
   "source": [
    "ANSWWER==\n",
    "Underfitting occurs when our machine learning model is not able to capture the underlying trend of the data. To avoid the overfitting in the model, the fed of training data can be stopped at an early stage, due to which the model may not learn enough from the training data. As a result, it may fail to find the best fit of the dominant trend in the data.\n",
    "Underfitting occurs when the model is too simple or when there is not enough training data to capture the true complexity of the problem. One common example of underfitting is when we use a linear model to fit a dataset that has a non-linear relationship between the input and output variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f327c6-f751-4c57-b973-5e76930a0621",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0659893-bf5b-42d2-9c79-ad6ccbe72832",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "Bias Variance Tradeoff is a design consideration when training the machine learning model. Certain algorithms inherently have a high bias and low variance and vice-versa. In this one, the concept of bias-variance tradeoff is clearly explained so you make an informed decision when training your ML models Bias Variance Tradeoff \n",
    "High Bias, Low Variance: A model with high bias and low variance is said to be underfitting.\n",
    "High Variance, Low Bias: A model with high variance and low bias is said to be overfitting.\n",
    "High-Bias, High-Variance: A model has both high bias and high variance, which means that the model is not able to capture the underlying patterns in the data (high bias) and is also too sensitive to changes in the training data (high variance). As a result, the model will produce inconsistent and inaccurate predictions on average.\n",
    "Low Bias, Low Variance: A model that has low bias and low variance means that the model is able to capture the underlying patterns in the data (low bias) and is not too sensitive to changes in the training data (low variance). This is the ideal scenario for a machine learning model, as it is able to generalize well to new, unseen data and produce consistent and accurate predictions. But in practice, it’s not possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7e4c8-f52a-446f-b065-e6930856d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767628e6-9ff6-4e76-a843-96648c96da64",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "UNDERFITTING AND Overfitting happens when we train a machine learning model too much tuned to the training set. As a result, the model learns the training data too well, but it can’t generate good predictions for unseen data.\n",
    "\n",
    "I understand that using cross validation we can validate our model, but it is also possible that maybe our model is underfitting; hence, providing wrong results. One possibility that I can think of is that if even after making our model less complex results are not right then our model might be underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6747476e-9a5b-46a3-83dd-76402097eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d82c1-ccf1-415c-be2f-1d2b7e5f3f07",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    "\n",
    " High-Bias, High-Variance: A model has both high bias and high variance, which means that the model is not able to capture the underlying patterns in the data (high bias) and is also too sensitive to changes in the training data (high variance). As a result, the model will produce inconsistent and inaccurate predictions on average.\n",
    "   High Bias, Low Variance: A model with high bias and low variance is said to be underfitting.\n",
    "     High Variance, Low Bias: A model with high variance and low bias is said to be overfitting.\n",
    "    Low Bias, Low Variance: A model that has low bias and low variance means that the model is able to capture the underlying patterns in the data (low bias) and is not too sensitive to changes in the training data (low variance). This is the ideal scenario for a machine learning model, as it is able to generalize well to new, unseen data and produce consistent and accurate predictions. But in practice, it’s not possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc59f5-1f0f-469b-b5ec-b42af89d646f",
   "metadata": {},
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b379b19f-db95-46d6-b5f4-b95a4a72c031",
   "metadata": {},
   "source": [
    "ANSWER==\n",
    " Regularization is one of the most important concepts of machine learning. It is a technique to prevent the model from overfitting by adding extra information to it. Sometimes the machine learning model performs well with the training data but does not perform well with the test data.\n",
    " \n",
    "   ne of the ways is to apply Regularization to the model. Regularization is a better technique than Reducing the number of features to overcome the overfitting problem as in Regularization we do not discard the features of the model. Regularization is a technique that penalizes the coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0970036-2166-4918-9371-a9e21f86dfb7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
